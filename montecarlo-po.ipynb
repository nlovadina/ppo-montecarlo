{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a reinterpretation of the Montecarlo examples on \"Professional product owner\" book by Don Mc Greal and Ralph Jocham. I used as an exercise to learn jupiter notebook and python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backlog_size = 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pb_montecarlo_loops = 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The book explains that there is a 75% probability of having the right estimation, 5% of having a smaller one and 20% of having a bigger one. I cannot find the source nor verify that affirmation, so I took it for granted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "poker_planning_values = [1,2,3,5,8,13,21]\n",
    "pb_montecarlo_simulation = []\n",
    "\n",
    "for pb_montecarlo_loop in range(pb_montecarlo_loops) :\n",
    "    sum = 0\n",
    "    for item in range(backlog_size) :\n",
    "        random_index = random.randrange(len(poker_planning_values)-1)\n",
    "        sum = sum + poker_planning_values[random_index]\n",
    "    pb_montecarlo_simulation.append(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.subplot(1,1,1)\n",
    "sns.distplot(pb_montecarlo_simulation)\n",
    "backlog_size = np.percentile(pb_montecarlo_simulation, 80)\n",
    "plt.title(\"Total effort Size Distribution in Story Points\")\n",
    "plt.axvline(x = backlog_size, color = 'red')\n",
    "plt.show()\n",
    "print(backlog_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(pb_montecarlo_simulation).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "velocity ={'worst':29, 'best':37}\n",
    "sprint_length = 10 \n",
    "s_montecarlo_loops = 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the possible date of completion the following formula is used:<br>\n",
    "$Time = (\\frac{Story Points_{Total}}{Velocity_{Average}})*Sprint Length$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = []\n",
    "velocities = []\n",
    "for i in range (s_montecarlo_loops):\n",
    "    sprints_to_finish = 0\n",
    "    finish = backlog_size\n",
    "    current_velocity = 0\n",
    "    while (finish>0):\n",
    "        current_velocity = random.randint(velocity['worst'], velocity['best'])\n",
    "        finish = finish - current_velocity\n",
    "        velocities.append(current_velocity)\n",
    "        sprints_to_finish = sprints_to_finish + 1\n",
    "    completion.append(sprints_to_finish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.subplot(1,1,1)\n",
    "sns.distplot(completion, kde=False)\n",
    "finishing_sprint = np.percentile(completion, 80)\n",
    "plt.title(\"Estimated Sprint for finish\")\n",
    "plt.axvline(x = finishing_sprint, color = 'red')\n",
    "plt.show()\n",
    "pd.Series(completion).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is another way to show up the data, histograms does not really look good. Images should look better. This is a #TODO. Then i generate a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sprint_counts = dict()\n",
    "x=[]\n",
    "y=[]\n",
    "\n",
    "for i in range(len(completion)-1):\n",
    "    sprint_counts[completion[i]] = sprint_counts.get(completion[i], 0) +1\n",
    "for value, count in sorted(sprint_counts.items()):\n",
    "    x.append(value)\n",
    "    y.append(count)\n",
    "    \n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(x,y)\n",
    "plt.title(\"Count of sprints for finishing\")\n",
    "plt.show()\n",
    "plt.subplot(2,1,2)\n",
    "plt.title(\"Estimated Sprint for finish\")\n",
    "plt.axvline(x = finishing_sprint, color = 'red')\n",
    "x = np.linspace(np.min(completion), np.max(completion), 1000000)\n",
    "from scipy.stats.distributions import norm\n",
    "y = norm.pdf(x, np.mean(completion), np.std(completion))\n",
    "plt.plot(x, y, color='orange')\n",
    "plt.show()\n",
    "\n",
    "print(finishing_sprint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I build a distribution using the mean and the standard deviation from the observations I calculate in the previous cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,1,1)\n",
    "plt.title(\"Estimated Sprint for finish\")\n",
    "x = np.linspace(np.min(completion), np.max(completion), 1000)\n",
    "from scipy.stats.distributions import norm\n",
    "y = norm.pdf(x, np.mean(completion), np.std(completion))\n",
    "plt.plot(x,y, color='blue')\n",
    "finishing_sprint = np.percentile(x, 95)\n",
    "plt.axvline(x = finishing_sprint, color = 'red')\n",
    "plt.show()\n",
    "print(finishing_sprint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(finishing_sprint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I attribute the varioation in the answer to the fact that in the second there are more points by constructions. To be discuss if a normal distribution is the good one to use. The result I obtain differs from the one of the book and in my version the result are more optimistic. I think I have to discuss it with the author."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
